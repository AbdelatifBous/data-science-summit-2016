{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class VideoCamera(object):\n",
    "    \n",
    "    def __init__(self, index=0):\n",
    "        self.video = cv2.VideoCapture(index)\n",
    "        self.index = index\n",
    "        self.is_opened = self.video.isOpened()\n",
    "        print self.video.isOpened()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "    \n",
    "    def get_frame(self, in_grayscale=False):\n",
    "        _, frame = self.video.read()\n",
    "        if in_grayscale:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "    \n",
    "class FaceDetector(object):\n",
    "    def __init__(self, xml_path):\n",
    "        self.classifier = cv2.CascadeClassifier(xml_path)\n",
    "    \n",
    "    def detect(self, image, biggest_only=True):\n",
    "        scale_factor = 1.2\n",
    "        min_neighbors = 5\n",
    "        min_size = (30, 30)\n",
    "        biggest_only = True\n",
    "        flags = cv2.CASCADE_FIND_BIGGEST_OBJECT | \\\n",
    "                    cv2.CASCADE_DO_ROUGH_SEARCH if biggest_only else \\\n",
    "                    cv2.CASCADE_SCALE_IMAGE\n",
    "        faces_coord = self.classifier.detectMultiScale(image,\n",
    "                                                       scaleFactor=scale_factor,\n",
    "                                                       minNeighbors=min_neighbors,\n",
    "                                                       minSize=min_size,\n",
    "                                                       flags=flags)\n",
    "        return faces_coord\n",
    "\n",
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x + w_rm, y), (x + w - w_rm, y + h), \n",
    "                              (150, 150, 0), 8)\n",
    "        \n",
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        w_rm = int(0.2 * w / 2)\n",
    "        faces.append(image[y: y + h, x + w_rm: x + w - w_rm])\n",
    "    return faces\n",
    "\n",
    "def resize(images, size=80):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            image_norm = cv2.resize(image, (size, size), \n",
    "                                    interpolation = cv2.INTER_AREA)\n",
    "        else:\n",
    "            image_norm = cv2.resize(image, (size, size), \n",
    "                                    interpolation = cv2.INTER_CUBIC)\n",
    "        images_norm.append(image_norm)\n",
    "    return images_norm \n",
    "        \n",
    "def plt_show(image, title=\"\"):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def normalize_faces(frame, faces_coord, img_size=80):\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = resize(faces, img_size)\n",
    "    return faces\n",
    "        \n",
    "# Open a new thread to manage the external cv2 interaction\n",
    "cv2.startWindowThread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 pictures every second\n",
    "num_pictures = 50\n",
    "img_size = 100\n",
    "\n",
    "webcam = VideoCamera()\n",
    "if webcam.is_opened:\n",
    "    detector = FaceDetector(\"xml/frontal_face.xml\")\n",
    "\n",
    "    pictures_folder = os.path.join('data', 'pictures_tf')\n",
    "    folder = os.path.join(pictures_folder, raw_input('Person: ').lower()) # input name\n",
    "    cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        counter = 1\n",
    "        while counter <= num_pictures : # take 20 pictures\n",
    "            frame = webcam.get_frame()\n",
    "            faces_coord = detector.detect(frame) # detect\n",
    "            if len(faces_coord): # every Second or so\n",
    "                faces = normalize_faces(frame, faces_coord, img_size) # norm pipeline\n",
    "                cv2.imwrite(folder + '/' + str(counter) + '.png', faces[0])\n",
    "                clear_output(wait = True) # saved face in notebook\n",
    "                counter += 1\n",
    "                clear_output(wait=True)\n",
    "                print counter\n",
    "            draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "            cv2.imshow(\"PyData Tutorial\", frame) # live feed in external\n",
    "            cv2.waitKey(250)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print \"This name already exists.\"\n",
    "del webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display a two random image from each letter in the train folder\n",
    "def print_images(folders):\n",
    "    images = []\n",
    "    for folder in folders:\n",
    "        images_path = os.listdir(folder)\n",
    "        random.choice(images_path)\n",
    "        for i in range(3):\n",
    "            image_path = os.path.join(folder,\n",
    "                                      random.choice(images_path))\n",
    "            frame = cv2.imread(image_path)\n",
    "            images.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.imshow(np.hstack(images))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print 'Maximum pixel intensity value: %.2f' %np.amax(images[0])\n",
    "    print 'Shape of images ' + str(images[0].shape) \n",
    "\n",
    "data_folders = os.listdir(os.path.join('data', 'pictures_tf'))\n",
    "data_folders = [os.path.join('data', 'pictures_tf', folder) for folder in data_folders]\n",
    "print_images(data_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 100 # pixel size\n",
    "num_imgs = 50 # images per class\n",
    "num_channels = 3\n",
    "num_classes = 2\n",
    "\n",
    "def number_of_images(folders):\n",
    "    \n",
    "    dataset = np.ndarray((num_imgs * num_classes, img_size, img_size, num_channels), dtype=np.int32)\n",
    "    labels = np.ndarray(num_imgs * num_classes, dtype=np.int32)\n",
    "    num_per_class = {}\n",
    "    counter = 0\n",
    "    for image_class, folder in enumerate(folders):\n",
    "        per_class_counter = 0\n",
    "        for image_name in os.listdir(folder):\n",
    "            if per_class_counter < num_imgs:\n",
    "                image_path = os.path.join(folder, image_name)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "#                     image = (image - np.max(image) / 2) / np.max(image)\n",
    "                    if image.shape == (img_size, img_size, num_channels):\n",
    "                        dataset[counter] = image\n",
    "                        labels[counter] = image_class\n",
    "                        counter += 1\n",
    "                        per_class_counter += 1\n",
    "                    else:\n",
    "                        raise Exception(\"Unexpected image shape\")\n",
    "                except Exception as e:\n",
    "                    print 'Unable to use image: ' + str(e)\n",
    "        num_per_class[image_class] = per_class_counter\n",
    "    return num_per_class, dataset, labels\n",
    "\n",
    "num_per_class, dataset, labels = number_of_images(data_folders)\n",
    "print 'Total number of images: %d' %dataset.shape[0]\n",
    "print 'Number of images per class:'\n",
    "print num_per_class\n",
    "images_per_class = np.amin(num_per_class.values())\n",
    "print 'We take %d images per class' %images_per_class\n",
    "print 'Images Shape:' + str(dataset[0].shape)\n",
    "print 'Dataset shape: ' + str(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = int(num_imgs * .65)\n",
    "print train_size\n",
    "valid_size = int(num_imgs * .2)\n",
    "print valid_size\n",
    "test_size = num_imgs - train_size - valid_size\n",
    "\n",
    "train_ds = np.ndarray((train_size * num_classes, img_size, img_size, num_channels),dtype=np.float32)\n",
    "train_lb = np.ndarray(train_size * num_classes, dtype=np.int32)\n",
    "\n",
    "valid_ds = np.ndarray((valid_size * num_classes, img_size, img_size, num_channels), dtype=np.float32)\n",
    "valid_lb = np.ndarray(valid_size * num_classes, dtype=np.int32)\n",
    "\n",
    "test_ds = np.ndarray((test_size * num_classes, img_size, img_size, num_channels), dtype=np.float32)\n",
    "test_lb = np.ndarray(test_size * num_classes, dtype=np.int32)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    start_set, end_set = i * num_imgs, (i + 1) * num_imgs\n",
    "    start_train, end_train = i * train_size, (i + 1) * train_size\n",
    "    start_valid, end_valid = i * valid_size, (i + 1) * valid_size\n",
    "    start_test, end_test = i * test_size, (i + 1) * test_size\n",
    "    \n",
    "    letter_set = dataset[start_set : end_set]\n",
    "    np.random.shuffle(letter_set)\n",
    "    \n",
    "    train_ds[start_train : end_train] = letter_set[0: train_size]\n",
    "    train_lb[start_train : end_train] = i\n",
    "    valid_ds[start_valid : end_valid] = letter_set[train_size: train_size + valid_size]\n",
    "    valid_lb[start_valid : end_valid] = i\n",
    "    test_ds[start_test : end_test] = letter_set[train_size + valid_size: train_size + valid_size + test_size]\n",
    "    test_lb[start_test : end_test] = i\n",
    "\n",
    "print(\"Train Shapes --> Dataset: %s   Labels: %s\" %(train_ds.shape, train_lb.shape))\n",
    "print(\"Valid Shapes --> Dataset: %s    Labels: %s\" %(valid_ds.shape, valid_lb.shape))\n",
    "print(\"Test Shapes  --> Dataset: %s    Labels: %s\" %(test_ds.shape, test_lb.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_ds = dataset[permutation]\n",
    "    shuffled_lb = labels[permutation]\n",
    "    return shuffled_ds, shuffled_lb\n",
    "\n",
    "train_ds, train_lb = randomize(train_ds, train_lb)\n",
    "test_ds, test_lb = randomize(test_ds, test_lb)\n",
    "valid_ds, valid_lb = randomize(valid_ds, valid_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat(dataset, labels):\n",
    "    # as.type is not needed as the array is already float32 but just in case\n",
    "    dataset = dataset.reshape((-1, img_size, img_size, num_channels)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_classes) == labels[:, None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_ds, train_lb = reformat(train_ds, train_lb)\n",
    "valid_ds, valid_lb = reformat(valid_ds, valid_lb)\n",
    "test_ds, test_lb = reformat(test_ds, test_lb)\n",
    "\n",
    "print(\"Train Shapes --> Dataset: %s   Labels: %s\" %(train_ds.shape, train_lb.shape))\n",
    "print(\"Valid Shapes --> Dataset: %s    Labels: %s\" %(valid_ds.shape, valid_lb.shape))\n",
    "print(\"Test Shapes  --> Dataset: %s    Labels: %s\" %(test_ds.shape, test_lb.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return 100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "patch_size = 5\n",
    "depth1 = 2\n",
    "# depth2 = 16\n",
    "# num_hidden = 4\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data\n",
    "    tf_train_ds = tf.placeholder(tf.float32, shape=(batch_size, img_size, img_size, num_channels))\n",
    "    tf_train_lb = tf.placeholder(tf.float32, shape=(batch_size, num_classes))\n",
    "    tf_valid_ds = tf.constant(valid_ds)\n",
    "    tf_test_ds = tf.constant(test_ds)\n",
    "    \n",
    "    # Variables.\n",
    "#     patch1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth1], stddev=0.1))\n",
    "#     patch1_biases = tf.Variable(tf.zeros([depth1]))\n",
    "    \n",
    "#     patch2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth1, depth2], stddev=0.1))\n",
    "#     patch2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]))\n",
    "    \n",
    "    # divided by four because that is the size once the patches have scanned the image\n",
    "#     layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "#                                  [img_size // 4 * img_size // 4 * depth1, num_classes], stddev=0.1))\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "                                 [img_size * img_size * num_channels, num_classes], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.constant(1.0, shape=[num_classes]))\n",
    "    \n",
    "    \n",
    "#     layer2_weights = tf.Variable(tf.truncated_normal([num_hidden, num_classes], stddev=0.1))\n",
    "#     layer2_biases = tf.Variable(tf.constant(1.0, shape=[num_classes]))\n",
    "    \n",
    "    # Model\n",
    "    def model(data, training):\n",
    "        # first convolution layer. Stride only matter in two elements in the middle\n",
    "#         conv = tf.nn.conv2d(data, patch1_weights, [1, 4, 4, 1], padding=\"SAME\")\n",
    "#         conv = tf.nn.max_pool(conv1 + patch1_biases, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\" )\n",
    "#         conv = tf.nn.relu(conv)\n",
    "        \n",
    "        # second convolution layer\n",
    "#         conv = tf.nn.conv2d(conv, patch2_weights, [1, 2, 2, 1], padding=\"SAME\")\n",
    "#         conv = tf.nn.max_pool(conv + patch2_biases, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\" )\n",
    "#         conv = tf.nn.relu(conv)\n",
    "\n",
    "        # reshape to apply fully connected layer\n",
    "#         shape_conv = conv.get_shape().as_list()\n",
    "#         input_hidden = tf.reshape(conv, [shape_conv[0], shape_conv[1] * shape_conv[2] * shape_conv[3]])\n",
    "        input_hidden = tf.reshape(data, [-1, img_size * img_size * num_channels])\n",
    "#         hidden_layer = tf.nn.relu(tf.matmul(input_hidden, layer1_weights) + layer1_biases)\n",
    "        \n",
    "        # adding dropout layer\n",
    "#         if training:\n",
    "#             hidden_layer = tf.nn.dropout(hidden_layer, 0.6)\n",
    "        \n",
    "        return tf.matmul(input_hidden, layer1_weights) + layer1_biases\n",
    "#         return tf.matmul(hidden_layer, layer2_weights) + layer2_biases\n",
    "    \n",
    "    # training computation\n",
    "    logits = model(tf_train_ds, True)\n",
    "    regularization = 0 #tf.nn.l2_loss(layer1_weights) #+ tf.nn.l2_loss(layer2_weights)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_lb)) + \\\n",
    "           .0005 * regularization\n",
    "    \n",
    "    # Optimizer\n",
    "    global_step = tf.Variable(0)\n",
    "#     learning_rate = tf.train.exponential_decay(0.05, global_step, 200, 0.95, staircase = True)\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(.05).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_ds, False))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_ds, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 101\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # randomize offset\n",
    "        offset = (step * batch_size) % (train_lb.shape[0] - batch_size)\n",
    "        batch_ds = train_ds[offset:(offset + batch_size)]\n",
    "        batch_lb = train_lb[offset:(offset + batch_size)]\n",
    "        \n",
    "        feed_dict = {tf_train_ds : batch_ds, tf_train_lb : batch_lb}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_lb))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "            valid_prediction.eval(), valid_lb))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
